services:
  rag-app:
    build: .
    container_name: rag-app
    ports:
      - "8501:8501"
    volumes:
      - ./docs:/app/docs
      - ./faiss_indexes:/app/faiss_indexes
      - ./logs:/app/logs
    environment:
      # This allows the app to find the ollama service on the Docker network
      - OLLAMA_BASE_URL=http://ollama:11434
    depends_on:
      ollama:
        condition: service_healthy
    networks:
      - rag-net

  ollama:
    # Build a custom ollama image that includes the model
    build:
      context: .
      dockerfile: Dockerfile.ollama
      args:
        - MODEL=mistral # Specify the model to pre-load here
    container_name: ollama
    volumes:
      - ./ollama_data:/root/.ollama
    healthcheck:
      # Test that the ollama server is running and responsive.
      test: ["CMD", "curl", "-f", "http://127.0.0.1:11434"]
      interval: 5s
      # Give the container a 3-minute grace period to start up and load the model.
      start_period: 180s
      timeout: 10s
      retries: 5
    networks:
      - rag-net

networks:
  rag-net:
    driver: bridge